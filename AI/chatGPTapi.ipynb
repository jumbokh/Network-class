{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/Network-class/blob/main/AI/chatGPTapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9eZ7rCsLl7s",
        "outputId": "f8ffcb11-c093-489a-de60-40c971756069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=b665f669ba99c93c43b8388b888e49d927a1e7344a9d278606b692dcc5d60e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "Fa3uGDX6Losq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string=\"\"\"rewrite the page:\n",
        "The code length of BCH(15, 7, 5) is n = 15, the message length is k = 7, \n",
        "the error resolution capability is t = 2, and the code rate is 7/15 = 0.46.\n",
        "As shown in 6.2.5 and 6.2.6, the bit error rate of Proposed network architecture is better than that of Chase-II approaching OSD,Proposed only took two candidate codewords, 21 less than Chase-II, and far less than the 121 candidate codewords of OSD(2). According to the experimental results, no matter what kind of training data set and signal-to-noise ratio is used, a similar bit error rate can be obtained.\n",
        "\n",
        "Each soft-decision decoding method adopts the network architecture with the best bit error rate among the above, as shown in 6.2.7 and 6.2.8. No matter what kind of soft decision decoding method is better than HDD, Regression belongs to the architecture with the worst bit error rate in soft decision, and the bit error rate of literature [12] and Proposed is better than Chase-II, and Proposed is better than literature [12] 12] also approximates OSD(2).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bCAYWmeHievN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine = \"text-davinci-003\",\n",
        "    prompt=string,\n",
        "    max_tokens=1024,\n",
        "    temperature=1,\n",
        "    top_p=0.75,\n",
        "    n=1\n",
        ")\n",
        "completed_text = response[\"choices\"][0][\"text\"]\n",
        "print(completed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwmDJVvjMMgz",
        "outputId": "3a633ccf-6360-4298-cdf4-39abfae0ac40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The BCH code with parameters (15, 7, 5) has a code length of n = 15, a message length of k = 7, an error resolution capability of t = 2, and a code rate of 7/15 = 0.46. According to 6.2.5 and 6.2.6, the Proposed network architecture has a better bit error rate than that of Chase-II and OSD(2). The experiments show that no matter the training data set or signal-to-noise ratio, a similar bit error rate can be obtained. 6.2.7 and 6.2.8 reveal that, among the soft decision decoding methods, the one with the best bit error rate is used. Regression has the worst bit error rate in the soft decision, while the bit error rate of literature [12] and Proposed is better than that of Chase-II, and Proposed is better than that of literature [12], and approximates OSD(2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string1=\"\"\"\n",
        "The code length of BCH(15, 5, 7) is n = 15, the message length is k = 5, the error resolution ability is t = 3, and its code rate is 5/15 = 0.33.\n",
        "As shown in 6.3.5 and 6.3.6, the bit error rate of Proposed network architecture is better than that of Chase-II, approaching OSD, while Proposed only takes four candidate codewords, 21 less than Chase-II, and far There are less than 121 candidate codewords of OSD(2). According to the experimental results, no matter what kind of training data set and signal-to-noise ratio is used, a similar bit error rate can be obtained.\n",
        "Each soft-decision decoding method adopts the network architecture with the best bit error rate among the above, as shown in 6.3.7 and 6.3.8.\n",
        "No matter which soft decision decoding method is better than HDD, the literature [11] belongs to the worst bit error rate in soft decision\n",
        "architecture, while Proposed BER is better than Chase-II and comparable to OSD(2).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4YRShMvsN0JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine = \"text-davinci-003\",\n",
        "    prompt=string1,\n",
        "    max_tokens=1024,\n",
        "    temperature=1,\n",
        "    top_p=0.75,\n",
        "    n=1\n",
        ")\n",
        "completed_text = response[\"choices\"][0][\"text\"]\n",
        "print(completed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5JLF54mpPKq",
        "outputId": "fc037c5e-d587-4b81-943f-6ed5d55fc78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The proposed BCH(15, 5, 7) code has a code rate of 0.33 and an error resolution ability of t = 3. The proposed network architecture was tested with different training data sets and signal-to-noise ratios and showed better bit error rate performance than Chase-II and comparable to OSD(2). The proposed architecture with the best bit error rate was adopted for both soft-decision decoding methods and showed a better bit error rate than HDD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string2=\"\"\"\n",
        "The code length of BCH(31, 11) is n = 31, the message length is k = 11, the error resolution ability is t = 5, and the code rate is 11/31 = 0.35.\n",
        "As shown in 6.4.5 and 6.4.6, the bit error rate of Proposed network architecture is close to Chase-II, while Proposed only takes four candidate codewords, which is 87 less than Chase-II and far less than OSD (2) 1024 candidate codewords. According to the experimental results, no matter what kind of training data set and signal-to-noise ratio is used, the bit error rate can be similar, and the balanced training set can obtain a better bit error rate.\n",
        "Each soft-decision decoding method adopts the network architecture with the best bit error rate above, as shown in 6.4.7 and 6.4.8. Under this codeword, the network architectures of literature [11] and literature [12] have bit errors The rate is lower than that of HDD. In contrast, the bit error rate of the Proposed network architecture does not decrease significantly due to the increase of the code length and t.\n",
        "Still on par with Chase-II and OSD(2).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rItt4XUTphSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine = \"text-davinci-003\",\n",
        "    prompt=string2,\n",
        "    max_tokens=1024,\n",
        "    temperature=1,\n",
        "    top_p=0.75,\n",
        "    n=1\n",
        ")\n",
        "completed_text = response[\"choices\"][0][\"text\"]\n",
        "print(completed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1oeAJc4prmG",
        "outputId": "74c7aa10-be69-4d26-b421-82ba63176ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The bit error rate of the Proposed network architecture is close to Chase-II, while the Proposed only takes four candidate codewords, which is 87 less than Chase-II and far less than OSD(2) 1024 candidate codewords. This shows that the Proposed network architecture has a good bit error rate even with a low number of candidate codewords.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string3=\"\"\"\n",
        "The code length of QR(23, 12, 7) is n = 23, the message length is k = 12, the error resolution capability is t = 3, and the code rate is 12/23 = 0.52.\n",
        "As shown in 6.5.5 and 6.5.6, the bit error rate of Proposed network architecture is close to that of Chase-II, while Proposed only takes four candidate codewords, which is 21 less than Chase-II and far less than OSD (2) 277 candidate codewords. According to the experimental results, no matter which training data set or signal-to-noise ratio is used, a similar bit error rate can be obtained, and a better bit error rate can be obtained by using a balanced training set.\n",
        "Each soft-decision decoding method adopts the network architecture with the best bit error rate among the above, as shown in 6.5.7 and 6.5.8. Under this codeword, the network architectures of literature [11] and literature [12] have bit errors The rate is lower than that of HDD. In contrast, the bit error rate of the Proposed network architecture does not decrease significantly due to the increase of the code length and t.\n",
        "Still on par with Chase-II and OSD(2).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yMlPNVA3pt-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "    engine = \"text-davinci-003\",\n",
        "    prompt=string3,\n",
        "    max_tokens=1024,\n",
        "    temperature=1,\n",
        "    top_p=0.75,\n",
        "    n=1\n",
        ")\n",
        "completed_text = response[\"choices\"][0][\"text\"]\n",
        "print(completed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seLpcJDQqP6f",
        "outputId": "256330b4-d7a0-44ff-bf87-19843ee5ffc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The results of 6.5.7 and 6.5.8 show that the Proposed network architecture is suitable for different lengths and different code rates. In terms of the bit error rate, it is on par with Chase-II and OSD(2). In terms of code length and error resolution capability, the Proposed network architecture has better scalability than Chase-II and OSD(2).\n"
          ]
        }
      ]
    }
  ]
}